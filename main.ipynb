{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "TODO:\n",
    "- Frame the business problem (why we care) and 3-5 potential use cases for this technology in the retail sector\n",
    "- Define success in terms of 1-2 specific metrics (recommend using MAPE and RMSE)\n",
    "- Provide a high-level overview of your approach\n",
    "- Write a high-level overview of your data\n",
    "    - Where it came from\n",
    "    - How it was collected\n",
    "    - Potential biases it may have\n",
    "- When you're all finished, write a 1-paragraph executive summary for this engagement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import\n",
    "\n",
    "TODO:\n",
    "- Load pkl into a dask dataframe for parallelized processing\n",
    "- Print .head() and .summary()\n",
    "\n",
    "OPTIONAL:\n",
    "- Distributively process your code using dask. See here: https://docs.dask.org/en/latest/setup/cloud.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import dask.dataframe as dd\n",
    "from datetime import timedelta\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "import shap\n",
    "\n",
    "# Import UDFs\n",
    "import sys\n",
    "sys.path.append('./src')\n",
    "from utilities import *\n",
    "from exploration import *\n",
    "from feature_engineering import *\n",
    "from modeling import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas_df = pd.read_pickle(\"./data/raw_weekly_df.pkl\")\n",
    "dask_df = dd.from_pandas(pandas_df, npartitions=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 6841121 entries, 0 to 6841120\nData columns (total 7 columns):\n #   Column    Dtype         \n---  ------    -----         \n 0   dept_id   category      \n 1   cat_id    category      \n 2   item_id   category      \n 3   state_id  category      \n 4   store_id  category      \n 5   datetime  datetime64[ns]\n 6   sales     float32       \ndtypes: category(5), datetime64[ns](1), float32(1)\nmemory usage: 117.5 MB\n"
    }
   ],
   "source": [
    "(pandas_df.info(memory_usage=\"Deep\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "arg must be a list, tuple, 1-d array, or Series",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-cdbf2ef37199>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m             \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcolumn_list\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhandle_numeric_downcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcolumn_list\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtype_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m \u001b[0mcompress_dataframe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpandas_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-9-cdbf2ef37199>\u001b[0m in \u001b[0;36mcompress_dataframe\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m     22\u001b[0m             \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcolumn_list\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcolumn_list\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'category'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m             \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcolumn_list\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhandle_numeric_downcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcolumn_list\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtype_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[0mcompress_dataframe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpandas_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-cdbf2ef37199>\u001b[0m in \u001b[0;36mhandle_numeric_downcast\u001b[1;34m(array, type_)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mhandle_numeric_downcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtype_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numeric\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdowncast\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtype_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mtype_\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"integer\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"float\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"object\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\numeric.py\u001b[0m in \u001b[0;36mto_numeric\u001b[1;34m(arg, errors, downcast)\u001b[0m\n\u001b[0;32m    135\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"O\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ndim\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 137\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"arg must be a list, tuple, 1-d array, or Series\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    138\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: arg must be a list, tuple, 1-d array, or Series"
     ]
    }
   ],
   "source": [
    "#Unable to allocate 365. MiB for an array with shape (7, 6841121) and data type float64 error?\n",
    "compress_dataframe(pandas_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration & Transformation\n",
    "\n",
    "TODO:\n",
    "- Check for outliers and missing data\n",
    "- Check for duplicates\n",
    "- Check datatypes and comment on whether they make sense\n",
    "- Plot univariate / bivariate graphs to better understand your data, especially for your target variable, in seaborn\n",
    "- Standardize, normalize, or log your target variable\n",
    "- Split your data into training, testing, and holdout sets and explain why this step is important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas_df.duplicated()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- shows that none of the rows are duplicated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas_df.loc[pandas_df.duplicated() != False]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - 6841121 cells of data are in the data set\n",
    " - the mean of the sales from all pieces of data is 9.60301\n",
    " - the range of the sales from the data is 0 to 4220\n",
    " - the distribution of the data shows 25% of the sales data having a value below 0, 50% of the sales data having a value below 3 (median), and 75% of the sales data having a value below 9\n",
    " - the sales data is skewed right since the mean is greater than the median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6.841121e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>9.526814e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.519556e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>9.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.220000e+03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              sales\n",
       "count  6.841121e+06\n",
       "mean   9.526814e+00\n",
       "std    2.519556e+01\n",
       "min    0.000000e+00\n",
       "25%    0.000000e+00\n",
       "50%    3.000000e+00\n",
       "75%    9.000000e+00\n",
       "max    4.220000e+03"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandas_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The majority of sales are between 0 and 10, with most sales falling at 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO source files shouldn't call functions; move to .main\n",
    "univariate_sales_histogram(pandas_df, \"sales\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of all three states, CA has the most number of sales (around 700,000 sales at 0.0) as compared to Wisconsin and Texas.\n",
    "This makes sense since California has the largest population compared to the other two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bivariate_sales_by_state(pandas_df, \"sales\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous observation, CA was observed to have the most number of 0.0 sales compared to the other two states. However, through this histogram, we see that CA actually has more stores than Texas and Wisconsin. All the graphs of the stores seem pretty similar, but if you observe closely, CA_1, CA_2, CA_3 (especially CA_3), CA_4, TX_1, TX_2 all have sales between 30 and 50 as well, unlike the other stores. This makes sense as well since CA has the largest population compared to the other two states, and compared to Wisconsin, Texas has a larger population.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bivariate_sales_by_store(pandas_df, \"sales\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO split these up into markdown cells (see examples above)\n",
    "sales_boxplot(pandas_df, \"sales\")\n",
    "\"\"\"The max sales value, 4220 is clearly an outlier. There also seem to be 6 other outliers since they are separate. All the outliers are larger not smaller.\"\"\"\n",
    "\"\"\"California has this outlier which is the largest value; this makes sense since California has a larger amount of people who contribute to these larger outliers occassionally.\"\"\"\n",
    "sales_box_plot_by_state_id(pandas_df, \"sales\")\n",
    "\"\"\"California has the largest value, 4220, which is also its largest outlier. California has 2 outliers that are \n",
    "at least 1000 more than the maximum in its data. Texas and Wisconsin have outliers that are smaller than 2000. Wisconsin has the least number of outliers.\"\"\"\n",
    "sales_box_plot_by_store_id(pandas_df, \"sales\")\n",
    "\"\"\"Every store's outliers are beneath 2000 except for CA_3, all of whose outliers crossed 2000.\n",
    "Since the range for CA_3 is higher than that of every other store, it indicates that CA_3 had the most sales.\"\"\"\n",
    "\"\"\"This makes sense since California has the largest population, so there will be more sales and larger outliers.\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap_to_see_missing_data(pandas_df)\n",
    "\"\"\"The heatmap has a display column for each series in a pandadataframe, and will have horizontal rows within each column wherever there are missing values/data (NaN). In this case, there aren't any missing data so the heatmap is empty.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "\n",
    "TODO:\n",
    "- Discretize any categorical features\n",
    "- Develop 3+ new time-related features and 3+ new product-related features as functions in a script called 'feature_engineering.py' in ./src\n",
    "    - Time-related features: MonthYear, holiday flags, etc.\n",
    "    - Product-related features: average number of items sold per month in each store (frequency), last time product sold in the store (recency), etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         -0.259046\n",
       "1         -0.020909\n",
       "2         -0.020909\n",
       "3         -0.060599\n",
       "4          0.177539\n",
       "             ...   \n",
       "6841116   -0.378115\n",
       "6841117   -0.378115\n",
       "6841118   -0.378115\n",
       "6841119   -0.378115\n",
       "6841120   -0.378115\n",
       "Name: sales, Length: 6841121, dtype: float32"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standardize(pandas_df,'sales')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           3.0\n",
       "1           9.0\n",
       "2           9.0\n",
       "3           8.0\n",
       "4          14.0\n",
       "           ... \n",
       "6841116     0.0\n",
       "6841117     0.0\n",
       "6841118     0.0\n",
       "6841119     0.0\n",
       "6841120     0.0\n",
       "Name: sales, Length: 6841121, dtype: float32"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unstandardize(standardize(pandas_df,'sales'),'sales')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CA</th>\n",
       "      <td>10.585984</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4220.000488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TX</th>\n",
       "      <td>9.033415</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1871.000122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WI</th>\n",
       "      <td>8.882002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1755.000122</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               mean  min          max\n",
       "state_id                             \n",
       "CA        10.585984  0.0  4220.000488\n",
       "TX         9.033415  0.0  1871.000122\n",
       "WI         8.882002  0.0  1755.000122"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stat_feature(pandas_df,'state_id','sales',['mean','min','max'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cumsum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6841116</th>\n",
       "      <td>65174088.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6841117</th>\n",
       "      <td>65174088.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6841118</th>\n",
       "      <td>65174088.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6841119</th>\n",
       "      <td>65174088.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6841120</th>\n",
       "      <td>65174088.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6841121 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             cumsum\n",
       "0               NaN\n",
       "1               3.0\n",
       "2              12.0\n",
       "3              21.0\n",
       "4              29.0\n",
       "...             ...\n",
       "6841116  65174088.0\n",
       "6841117  65174088.0\n",
       "6841118  65174088.0\n",
       "6841119  65174088.0\n",
       "6841120  65174088.0\n",
       "\n",
       "[6841121 rows x 1 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cum_stat(pandas_df,'state_id','sales')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          NaN\n",
       "1          6.0\n",
       "2          0.0\n",
       "3         -1.0\n",
       "4          6.0\n",
       "          ... \n",
       "6841116    0.0\n",
       "6841117    0.0\n",
       "6841118    0.0\n",
       "6841119    0.0\n",
       "6841120    0.0\n",
       "Name: sales, Length: 6841121, dtype: float32"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detrend_feature(pandas_df,'state_id','sales')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "\n",
    "TODO: \n",
    "- Write a function to run your lightgbm and xgboost models on your training data and output your in-sample and out-of-sample error RMSE and MAPE\n",
    "- Use your function to 'tune' both algorithms by passing in different combinations of hyperparameters (max depth, subsampling, etc.) to optimize for OOS RMSE\n",
    "- Plot your OOS RMSE on the y-axis and your various hyperparameter combinations on the x-axis to select the best combination\n",
    "- Retrain your models on your train + test data and measure your IS and OOS error metrics on your holdout data \n",
    "\n",
    "OPTIONAL:\n",
    "- Validate that your results are accurate using k-fold cross-validation. Note that this step is extremely important, but can be time-intensive; including it here as optional to be conscious of our time constraints."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpretation\n",
    "\n",
    "TODO:\n",
    "- Create a SHAP plot for our best model and interpret its results\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}