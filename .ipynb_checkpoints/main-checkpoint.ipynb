{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "TODO:\n",
    "- Frame the business problem (why we care) and 3-5 potential use cases for this technology in the retail sector\n",
    "- Define success in terms of 1-2 specific metrics (recommend using MAPE and RMSE)\n",
    "- Provide a high-level overview of your approach\n",
    "- Write a high-level overview of your data\n",
    "    - Where it came from\n",
    "    - How it was collected\n",
    "    - Potential biases it may have\n",
    "- When you're all finished, write a 1-paragraph executive summary for this engagement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import\n",
    "\n",
    "TODO:\n",
    "- Load pkl into a dask dataframe for parallelized processing\n",
    "- Print .head() and .summary()\n",
    "\n",
    "OPTIONAL:\n",
    "- Get a free student account to AWS EC2 / GCP and distributively process your code using dask. See here: https://docs.dask.org/en/latest/setup/cloud.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import dask as dd\n",
    "\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration & Transformation\n",
    "\n",
    "TODO:\n",
    "- Check for outliers and missing data\n",
    "- Check for duplicates\n",
    "- Check datatypes and comment on whether they make sense\n",
    "- Plot univariate / bivariate graphs to better understand your data, especially for your target variable, in seaborn\n",
    "- Standardize, normalize, or log your target variable\n",
    "- Split your data into training, testing, and holdout sets and explain why this step is important"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "\n",
    "TODO:\n",
    "- Discretize any categorical features\n",
    "- Develop 3+ new time-related features and 3+ new product-related features as functions in a script called 'feature_engineering.py' in ./src\n",
    "    - Time-related features: MonthYear, holiday flags, etc.\n",
    "    - Product-related features: average number of items sold per month in each store (frequency), last time product sold in the store (recency), etc. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "\n",
    "TODO: \n",
    "- Write a function to run your lightgbm and xgboost models on your training data and output your in-sample and out-of-sample error RMSE and MAPE\n",
    "- Use your function to 'tune' both algorithms by passing in different combinations of hyperparameters (max depth, subsampling, etc.) to optimize for OOS RMSE\n",
    "- Plot your OOS RMSE on the y-axis and your various hyperparameter combinations on the x-axis to select the best combination\n",
    "- Retrain your models on your train + test data and measure your IS and OOS error metrics on your holdout data \n",
    "\n",
    "OPTIONAL:\n",
    "- Validate that your results are accurate using k-fold cross-validation. Note that this step is extremely important, but can be time-intensive; including it here as optional to be conscious of our time constraints."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpretation\n",
    "\n",
    "TODO:\n",
    "- Create a SHAP plot for our best model and interpret its results\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
